{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b620e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch_tensorrt\n",
    "from torch_tensorrt._enums import memory_format\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"To copy construct from a tensor, it is recommended to use sourceTensor.detach\\\\(\\\\).clone\\\\(\\\\)\",\n",
    "    category=UserWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47b0d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/ubuntu/ttrt-env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "\n",
      "WARNING:py.warnings:/home/ubuntu/ttrt-env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare models, one for fp32 and another for fp16\n",
    "base_model = models.resnet18(pretrained=True).eval().cuda()\n",
    "base_model = base_model.to(memory_format=torch.channels_last)\n",
    "model_fp16 = models.resnet18(pretrained=True).eval().cuda()\n",
    "model_fp16 = model_fp16.to(memory_format=torch.channels_last)\n",
    "model_fp16 = model_fp16.half() # for fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f92aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(model, input_tensor,\n",
    "                    warmup_iters: int = 15,\n",
    "                    timed_iters: int = 100):\n",
    "    # Warm‑up\n",
    "    for _ in range(warmup_iters):\n",
    "        _ = model(input_tensor)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    times = []\n",
    "    for _ in range(timed_iters):\n",
    "        t0 = time.time()\n",
    "        _ = model(input_tensor)\n",
    "        torch.cuda.synchronize()\n",
    "        t1 = time.time()\n",
    "        times.append((t1 - t0) * 1000)  # ms\n",
    "\n",
    "    times = np.array(times)\n",
    "    print(f\"    → mean: {times.mean():.2f} ms  ±  std: {times.std():.2f} ms\")\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ef279f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch size 1 ===\n",
      " Timing  (ms):\n",
      "  PyTorch FP32:    → mean: 4.28 ms  ±  std: 0.68 ms\n",
      "  TRT FP32:       → mean: 3.17 ms  ±  std: 0.71 ms\n",
      "  TRT FP16:       → mean: 3.05 ms  ±  std: 0.70 ms\n",
      " PyTorch profiling trace saved for batch 1\n",
      " TRT FP32 profiling trace saved for batch 1\n",
      " TRT FP16 profiling trace saved for batch 1\n",
      "\n",
      "=== Batch size 8 ===\n",
      " Timing  (ms):\n",
      "  PyTorch FP32:    → mean: 9.17 ms  ±  std: 0.11 ms\n",
      "  TRT FP32:       → mean: 7.84 ms  ±  std: 0.08 ms\n",
      "  TRT FP16:       → mean: 4.57 ms  ±  std: 1.06 ms\n",
      " PyTorch profiling trace saved for batch 8\n",
      " TRT FP32 profiling trace saved for batch 8\n",
      " TRT FP16 profiling trace saved for batch 8\n",
      "\n",
      "=== Batch size 16 ===\n",
      " Timing  (ms):\n",
      "  PyTorch FP32:    → mean: 17.13 ms  ±  std: 0.23 ms\n",
      "  TRT FP32:       → mean: 14.12 ms  ±  std: 0.15 ms\n",
      "  TRT FP16:       → mean: 6.22 ms  ±  std: 1.13 ms\n",
      " PyTorch profiling trace saved for batch 16\n",
      " TRT FP32 profiling trace saved for batch 16\n",
      " TRT FP16 profiling trace saved for batch 16\n",
      "\n",
      "=== Batch size 32 ===\n",
      " Timing  (ms):\n",
      "  PyTorch FP32:    → mean: 35.75 ms  ±  std: 0.23 ms\n",
      "  TRT FP32:       → mean: 27.53 ms  ±  std: 0.20 ms\n",
      "  TRT FP16:       → mean: 9.99 ms  ±  std: 0.70 ms\n",
      " PyTorch profiling trace saved for batch 32\n",
      " TRT FP32 profiling trace saved for batch 32\n",
      " TRT FP16 profiling trace saved for batch 32\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [1, 8, 16, 32]:\n",
    "    print(f\"\\n=== Batch size {batch_size} ===\")\n",
    "    input_shape = (batch_size, 3, 224, 224)\n",
    "    input_tensor = torch.randn(input_shape, device=\"cuda\") \\\n",
    "                         .to(memory_format=torch.channels_last)\n",
    "\n",
    "    # prepare output dirs\n",
    "    for tag in [\"pytorch\", \"trt_fp32\", \"trt_fp16\"]:\n",
    "        run_dir = f\"tb_logs/{tag}_bs{batch_size}\"\n",
    "        os.makedirs(os.path.join(run_dir, \"plugins\", \"profile\"), exist_ok=True)\n",
    "\n",
    "    # ----- Benchmark raw latencies -----\n",
    "    print(\" Timing  (ms):\")\n",
    "    print(\"  PyTorch FP32:\", end=\"\")\n",
    "    benchmark_model(base_model, input_tensor)\n",
    "    print(\"  TRT FP32:   \", end=\"\")\n",
    "    # compile once to get trt_model\n",
    "    trt_model = torch_tensorrt.compile(\n",
    "        base_model,\n",
    "        inputs=[torch_tensorrt.Input(\n",
    "            min_shape=input_shape,\n",
    "            opt_shape=input_shape,\n",
    "            max_shape=input_shape,\n",
    "            dtype=torch.float32,\n",
    "            format=torch.channels_last\n",
    "        )],\n",
    "        enabled_precisions={torch.float32},\n",
    "        method=\"fx\",\n",
    "        workspace_size=1 << 32\n",
    "    )\n",
    "    benchmark_model(trt_model, input_tensor)\n",
    "\n",
    "    print(\"  TRT FP16:   \", end=\"\")\n",
    "    trt_model_fp16 = torch_tensorrt.compile(\n",
    "        model_fp16,\n",
    "        inputs=[torch_tensorrt.Input(\n",
    "            min_shape=input_shape,\n",
    "            opt_shape=input_shape,\n",
    "            max_shape=input_shape,\n",
    "            dtype=torch.float16,\n",
    "            format=torch.channels_last\n",
    "        )],\n",
    "        enabled_precisions={torch.float16},\n",
    "        method=\"fx\",\n",
    "        workspace_size=1 << 32\n",
    "    )\n",
    "    input_tensor_fp16 = input_tensor.half()\n",
    "    benchmark_model(trt_model_fp16, input_tensor_fp16)\n",
    "\n",
    "    # ----- Profiling traces -----\n",
    "    # PyTorch FP32\n",
    "    run_dir = f\"tb_logs/pytorch_bs{batch_size}\"\n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "        record_shapes=True, profile_memory=True,\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(run_dir),\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "        for _ in range(50):\n",
    "            with record_function(\"pytorch_inference\"):\n",
    "                _ = base_model(input_tensor)\n",
    "            prof.step()\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\" PyTorch profiling trace saved for batch {batch_size}\")\n",
    "\n",
    "    # TRT FP32\n",
    "    run_dir = f\"tb_logs/trt_fp32_bs{batch_size}\"\n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "        record_shapes=True, profile_memory=True,\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(run_dir),\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "        for _ in range(50):\n",
    "            with record_function(\"trt_fp32_inference\"):\n",
    "                _ = trt_model(input_tensor)\n",
    "            prof.step()\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\" TRT FP32 profiling trace saved for batch {batch_size}\")\n",
    "\n",
    "    # TRT FP16\n",
    "    run_dir = f\"tb_logs/trt_fp16_bs{batch_size}\"\n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "        record_shapes=True, profile_memory=True,\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(run_dir),\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "        for _ in range(50):\n",
    "            with record_function(\"trt_fp16_inference\"):\n",
    "                _ = trt_model_fp16(input_tensor_fp16)\n",
    "            prof.step()\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\" TRT FP16 profiling trace saved for batch {batch_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttrt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
